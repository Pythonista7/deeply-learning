{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "xoSg4S0j03w5",
        "rjwFrO_IxD_J",
        "9Mvlhc6CzRim",
        "4s69QNoS4dsk",
        "Jm4FP3AJLaue"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Torch'ing things up!\n",
        "\n",
        "Lets start using torch !"
      ],
      "metadata": {
        "id": "yG1pzI3G0a98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tK0-YMQVgZa8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
        "    device = torch.device(\"cuda:0\") # Use the first GPU\n",
        "else:\n",
        "    print(\"No GPU available. Training will run on CPU.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIKc7ez_kBvG",
        "outputId": "7c342ded-623f-4781-9d92-50371944cf6f",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-40GB is available.\n",
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple example of a toy neural net in torch!\n",
        "\n",
        "This is just to warm up the brain for writing some code and also to have a reference for the basics of how torch should be used."
      ],
      "metadata": {
        "id": "xoSg4S0j03w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)"
      ],
      "metadata": {
        "id": "QQt6NgdxjZrS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = torch.nn.Sequential(\n",
        "      torch.nn.Linear(1, 10),\n",
        "      torch.nn.LeakyReLU(),\n",
        "      torch.nn.Linear(10, 10),\n",
        "      torch.nn.LeakyReLU(),\n",
        "      torch.nn.Linear(10, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "Uea8KAd3jmXy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x[:1600], x[1600:]\n",
        "y_train, y_test = y[:1600], y[1600:]\n",
        "\n",
        "x_train = x_train.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "x_train = x_train.unsqueeze(-1)\n",
        "x_test = x_test.unsqueeze(-1)\n"
      ],
      "metadata": {
        "id": "wzdERAi_j9N0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc4miOyIlZ0W",
        "outputId": "263a38d3-44fa-4618-c065-8ae28ee096f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
              "  (1): LeakyReLU(negative_slope=0.01)\n",
              "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (3): LeakyReLU(negative_slope=0.01)\n",
              "  (4): Linear(in_features=10, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "opt = torch.optim.Adagrad(params = model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "8LyYoJN97NzZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100"
      ],
      "metadata": {
        "id": "KPjUrudR8zCC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(epochs):\n",
        "  model.train(True)\n",
        "  preds = model(x_train)\n",
        "  loss = loss_fn(preds, y_train)\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  print(f\"Epoch: {e}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rELyspWx8jEG",
        "outputId": "0bbaaa62-8f82-4b86-914e-cd230431fc49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:132: UserWarning: Using a target size (torch.Size([1600])) that is different to the input size (torch.Size([1600, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.7965441346168518\n",
            "Epoch: 1, Loss: 0.7489492893218994\n",
            "Epoch: 2, Loss: 0.7229583859443665\n",
            "Epoch: 3, Loss: 0.7060922980308533\n",
            "Epoch: 4, Loss: 0.6943273544311523\n",
            "Epoch: 5, Loss: 0.6862462162971497\n",
            "Epoch: 6, Loss: 0.6807591915130615\n",
            "Epoch: 7, Loss: 0.6767178773880005\n",
            "Epoch: 8, Loss: 0.6733000874519348\n",
            "Epoch: 9, Loss: 0.6701703667640686\n",
            "Epoch: 10, Loss: 0.6672030091285706\n",
            "Epoch: 11, Loss: 0.6643455624580383\n",
            "Epoch: 12, Loss: 0.6616623997688293\n",
            "Epoch: 13, Loss: 0.6594176888465881\n",
            "Epoch: 14, Loss: 0.6574410200119019\n",
            "Epoch: 15, Loss: 0.6556175351142883\n",
            "Epoch: 16, Loss: 0.6539175510406494\n",
            "Epoch: 17, Loss: 0.6523216962814331\n",
            "Epoch: 18, Loss: 0.6508179306983948\n",
            "Epoch: 19, Loss: 0.6493966579437256\n",
            "Epoch: 20, Loss: 0.6480509638786316\n",
            "Epoch: 21, Loss: 0.6467753052711487\n",
            "Epoch: 22, Loss: 0.6455650925636292\n",
            "Epoch: 23, Loss: 0.6444168090820312\n",
            "Epoch: 24, Loss: 0.643326461315155\n",
            "Epoch: 25, Loss: 0.6422923803329468\n",
            "Epoch: 26, Loss: 0.6413148045539856\n",
            "Epoch: 27, Loss: 0.6403905153274536\n",
            "Epoch: 28, Loss: 0.6395153999328613\n",
            "Epoch: 29, Loss: 0.6386860013008118\n",
            "Epoch: 30, Loss: 0.6378996968269348\n",
            "Epoch: 31, Loss: 0.6371541023254395\n",
            "Epoch: 32, Loss: 0.6364477276802063\n",
            "Epoch: 33, Loss: 0.635779082775116\n",
            "Epoch: 34, Loss: 0.6351472735404968\n",
            "Epoch: 35, Loss: 0.6345506906509399\n",
            "Epoch: 36, Loss: 0.6339719295501709\n",
            "Epoch: 37, Loss: 0.6333871483802795\n",
            "Epoch: 38, Loss: 0.6328044533729553\n",
            "Epoch: 39, Loss: 0.6322831511497498\n",
            "Epoch: 40, Loss: 0.6318135261535645\n",
            "Epoch: 41, Loss: 0.631343424320221\n",
            "Epoch: 42, Loss: 0.6309258341789246\n",
            "Epoch: 43, Loss: 0.6305373907089233\n",
            "Epoch: 44, Loss: 0.6301442384719849\n",
            "Epoch: 45, Loss: 0.6297921538352966\n",
            "Epoch: 46, Loss: 0.6294616460800171\n",
            "Epoch: 47, Loss: 0.6291290521621704\n",
            "Epoch: 48, Loss: 0.6288244128227234\n",
            "Epoch: 49, Loss: 0.6285348534584045\n",
            "Epoch: 50, Loss: 0.6282619833946228\n",
            "Epoch: 51, Loss: 0.628001868724823\n",
            "Epoch: 52, Loss: 0.6277377009391785\n",
            "Epoch: 53, Loss: 0.6274946928024292\n",
            "Epoch: 54, Loss: 0.6272615194320679\n",
            "Epoch: 55, Loss: 0.627037763595581\n",
            "Epoch: 56, Loss: 0.6268228888511658\n",
            "Epoch: 57, Loss: 0.6266167759895325\n",
            "Epoch: 58, Loss: 0.6264196634292603\n",
            "Epoch: 59, Loss: 0.6262262463569641\n",
            "Epoch: 60, Loss: 0.626043975353241\n",
            "Epoch: 61, Loss: 0.6258611679077148\n",
            "Epoch: 62, Loss: 0.6256900429725647\n",
            "Epoch: 63, Loss: 0.6255239248275757\n",
            "Epoch: 64, Loss: 0.6253661513328552\n",
            "Epoch: 65, Loss: 0.6252052187919617\n",
            "Epoch: 66, Loss: 0.6250550746917725\n",
            "Epoch: 67, Loss: 0.6249107122421265\n",
            "Epoch: 68, Loss: 0.6247712969779968\n",
            "Epoch: 69, Loss: 0.6246317028999329\n",
            "Epoch: 70, Loss: 0.6245012879371643\n",
            "Epoch: 71, Loss: 0.624370813369751\n",
            "Epoch: 72, Loss: 0.624247133731842\n",
            "Epoch: 73, Loss: 0.6241252422332764\n",
            "Epoch: 74, Loss: 0.6240077614784241\n",
            "Epoch: 75, Loss: 0.6238937377929688\n",
            "Epoch: 76, Loss: 0.6237818598747253\n",
            "Epoch: 77, Loss: 0.6236754655838013\n",
            "Epoch: 78, Loss: 0.6235687136650085\n",
            "Epoch: 79, Loss: 0.6234678626060486\n",
            "Epoch: 80, Loss: 0.6233680844306946\n",
            "Epoch: 81, Loss: 0.6232726573944092\n",
            "Epoch: 82, Loss: 0.6231781244277954\n",
            "Epoch: 83, Loss: 0.623087465763092\n",
            "Epoch: 84, Loss: 0.6229987144470215\n",
            "Epoch: 85, Loss: 0.6229130625724792\n",
            "Epoch: 86, Loss: 0.6228287220001221\n",
            "Epoch: 87, Loss: 0.6227472424507141\n",
            "Epoch: 88, Loss: 0.6226679086685181\n",
            "Epoch: 89, Loss: 0.6225910186767578\n",
            "Epoch: 90, Loss: 0.6225153207778931\n",
            "Epoch: 91, Loss: 0.6224421858787537\n",
            "Epoch: 92, Loss: 0.6223709583282471\n",
            "Epoch: 93, Loss: 0.6223013401031494\n",
            "Epoch: 94, Loss: 0.6222337484359741\n",
            "Epoch: 95, Loss: 0.6221679449081421\n",
            "Epoch: 96, Loss: 0.622103750705719\n",
            "Epoch: 97, Loss: 0.6220412254333496\n",
            "Epoch: 98, Loss: 0.6219803690910339\n",
            "Epoch: 99, Loss: 0.6219210028648376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eval on test set\n",
        "model.train(False)\n",
        "preds = model(x_test)\n",
        "loss = loss_fn(preds, y_test)\n",
        "print(f\"Test Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kedv6Ga-p57",
        "outputId": "c07d7c40-1867-4de1-b8e6-0d41d736018a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.2500652074813843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:132: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([0.5]).to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJZ3Z5lg_D_9",
        "outputId": "27dcc86d-96f9-4949-98ff-64b97a99c33a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1791], device='cuda:0', grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sin(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Hp3FoxBfzj",
        "outputId": "4068fc44-0019-432c-aed9-27d6e23477c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.479425538604203)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Lets build a simple CNN and train it on MNIST using just torch autograd\n",
        "\n",
        "Ref: http://yann.lecun.com/exdb/publis/pdf/lecun-iscas-10.pdf\n",
        "\n",
        "\n",
        "First lets consider all the details , the CNN architecture mainly consists of 3 important pieces:\n",
        "1. The filter bank of kernals\n",
        "2. non-linearity\n",
        "3. feature pooling"
      ],
      "metadata": {
        "id": "xh4n9qbu0uVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device: \",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI_F3hTeQRvk",
        "outputId": "0b30f704-528f-42d8-e181-2103a95f0ccf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Conv Step with filters"
      ],
      "metadata": {
        "id": "rjwFrO_IxD_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First lets code up a convolution operation\n",
        "def do_conv(\n",
        "    x: torch.tensor,\n",
        "    kernel: torch.tensor,\n",
        "    bias: torch.tensor\n",
        "):\n",
        "  # Input will be a 3D Matrix\n",
        "  c,w,h = x.shape\n",
        "  print(f\"X shape is {x.shape}\")\n",
        "\n",
        "  # kernal is a 2d tensor\n",
        "  kc,kw,kh = kernel.shape\n",
        "  print(f\"kernel shape is {kernel.shape}\")\n",
        "\n",
        "  # Assumptions are best asserted in code.\n",
        "  assert(kc == c)\n",
        "\n",
        "  # output will be 3D matrix with results from the conv ops\n",
        "  out = torch.zeros((c,w-kw+1,h-kh+1), device=x.device)\n",
        "  print(f\"Output shape is {out.shape}\")\n",
        "\n",
        "  for j in range(w - kw + 1):\n",
        "    for k in range(h - kh + 1):\n",
        "      patch = x[:,j:j+kw,k:k+kh]\n",
        "      conv_result = torch.mul(patch,kernel)\n",
        "      out[:,j,k] = torch.sum(conv_result,dim=(1,2)) + bias\n",
        "\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "tFq5zgah1zXM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "m2g6KViUQqxJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C, H, W = 3, 7, 8\n",
        "KH, KW = 3, 3\n",
        "x = torch.randn(C, H, W, device=device)\n",
        "w = torch.randn(C, KH, KW, device=device)\n",
        "b = torch.tensor(0.1, device=device)\n",
        "\n",
        "print(f\"x device is {x.device}\")\n",
        "print(f\"w device is {w.device}\")\n",
        "print(f\"b device is {b.device}\")\n",
        "\n",
        "y_manual = do_conv(x, w, b)\n",
        "y_torch = F.conv2d(x.unsqueeze(0), w.unsqueeze(0), bias=b.unsqueeze(0)).squeeze(0).squeeze(0)\n",
        "print(\"Torch output shape: \",y_torch.shape)\n",
        "print(torch.max(torch.abs(y_manual - y_torch)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdkmIrMlS1Xn",
        "outputId": "07338c5e-91fd-4c28-b637-0a5e81b6f20a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x device is cuda:0\n",
            "w device is cuda:0\n",
            "b device is cuda:0\n",
            "X shape is torch.Size([3, 7, 8])\n",
            "kernel shape is torch.Size([3, 3, 3])\n",
            "Output shape is torch.Size([3, 5, 6])\n",
            "Torch output shape:  torch.Size([5, 6])\n",
            "tensor(11.7064, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that torch conv2d does something different from what we have implemented! The shape of the torch output is only a 2D tensor but we are generating a 3D tensor! The difference you ask? Let's Analyze!\n",
        "\n",
        "**Our implementation**\n",
        "- input x: shape `(C=3, H, W)`\n",
        "- kernel w: shape `(KH, KW)` - one 2D kernel and you loop over channels `i`\n",
        "- For each channel we independently compute `y_i = conv2d(x_i, w) + b`\n",
        "- This produces 3 separate output maps, i.e: one kernel is reused across all channels but the sum() op is done such that it only adds data from a single channel and never across channels.\n",
        "\n",
        "> This is basically depthwise conv with a shared kernel (depthwise usually uses different kernels per channel, but the “no mixing” between the channels part is the key).\n",
        "\n",
        "\n",
        "**What torch is doing**\n",
        "- weight shape is `(C_out, C_in, KH, KW)`\n",
        "- So when we say we want the output should be `C_out = 1, C_in = 3`, the channels are \"mixed\"(summed) over into one output map.\n",
        "\n",
        "This is why you can see in the output of the previous cell:\n",
        "```\n",
        "Output shape is torch.Size([3, 5, 6])\n",
        "Torch output shape:  torch.Size([5, 6])\n",
        "```\n",
        "Our implementation outputs an extra \"channel\" dimension while the torch output has already summed over that axis.\n",
        "\n",
        "\n",
        "So lets make that small change and compare the values again!\n",
        "\n"
      ],
      "metadata": {
        "id": "UinzITOqiHpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_like_torch(\n",
        "    x: torch.Tensor,               # (C_in, H, W)\n",
        "    w: torch.Tensor,               # (C_out, C_in, KH, KW)\n",
        "    b: torch.Tensor | None = None  # (C_out,) or None\n",
        ") -> torch.Tensor:\n",
        "  # print(f\"x shape is {x.shape} | {x.device}\")\n",
        "  # print(f\"w shape is {w.shape} | {w.device}\")\n",
        "  C_in, H, W = x.shape\n",
        "  C_out, C_in_w, KH, KW = w.shape\n",
        "  assert C_in == C_in_w\n",
        "\n",
        "  out_h = H - KH + 1\n",
        "  out_w = W - KW + 1\n",
        "  out = torch.zeros((C_out, out_h, out_w), dtype=x.dtype, device=x.device)\n",
        "\n",
        "  for oc in range(C_out):\n",
        "    for j in range(out_h):\n",
        "      for k in range(out_w):\n",
        "        patch = x[:, j:j+KH, k:k+KW]          # (C_in, KH, KW)\n",
        "        out[oc, j, k] = (patch * w[oc]).sum() # sum over C_in,KH,KW\n",
        "        if b is not None:\n",
        "          out[oc, j, k] += b[oc]\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "cLcM7bDniStI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C, H, W = 3, 12, 12\n",
        "KH, KW = 3, 3\n",
        "\n",
        "out_channels = 6\n",
        "x = torch.randn(C, H, W, device=device)\n",
        "w = torch.randn(out_channels,C,KH, KW,device=device) # Changed\n",
        "b = torch.tensor(0.1,device=device).repeat((out_channels,)) # Changed\n",
        "\n",
        "y_manual = conv2d_like_torch(x, w, b)\n",
        "y_torch = F.conv2d(\n",
        "    input = x.unsqueeze(0),\n",
        "    weight = w, # Corrected weight shape\n",
        "    bias = b, # Corrected bias shape\n",
        ").squeeze(0) # Removed one squeeze operation\n",
        "print(\"Manual output shape:\",y_manual.shape)\n",
        "print(\"Torch output shape: \",y_torch.shape)\n",
        "print(torch.max(torch.abs(y_manual - y_torch)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WdbKQwvi9ym",
        "outputId": "84c7fab1-9898-4809-da13-88753659eebf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual output shape: torch.Size([6, 10, 10])\n",
            "Torch output shape:  torch.Size([6, 10, 10])\n",
            "tensor(2.8610e-06, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! we have a conv2d op that kinda works just like how torch does it, we still are missing some small pieces like stride and padding but the core is key!\n",
        "\n",
        "Next lets build the non-linearity step!"
      ],
      "metadata": {
        "id": "cfWhd7Q0yyHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Non-Linearity\n",
        "\n",
        "Here we can write a simple ReLU or activation function, the idea is basically that this activation fn is applied per element over the output. We've implemented relu and leaky-relu in the previous notebook so I'll just goahead and use the torch version here."
      ],
      "metadata": {
        "id": "9Mvlhc6CzRim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv2d_like_torch(x, w, b)\n",
        "print(out.shape)\n",
        "z = F.relu(out)\n",
        "print(z.shape)\n",
        "\n",
        "print(out[0])\n",
        "print(\"\"\"\n",
        "Conv Outputs ^^\n",
        "\n",
        "==========\n",
        "Notice how the function is applied element-wise!\n",
        "==========\n",
        "\n",
        "After Activation\n",
        "\"\"\")\n",
        "print(z[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV1Y17Gt0b-z",
        "outputId": "13b8f7cc-21ed-473d-c173-8acf968c4af3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 10, 10])\n",
            "torch.Size([6, 10, 10])\n",
            "tensor([[ -4.2628,   4.0931,   2.7057,  -1.3682,   8.3933,   0.3624,   4.4993,\n",
            "          -0.0514,  -2.0500,   3.8652],\n",
            "        [ -8.7030,   8.9368,   5.4750,   0.8334,   2.5965,  10.3463, -16.3020,\n",
            "          -2.0522,  17.8576,  -4.7644],\n",
            "        [  0.0597, -11.6700,   4.4270,  -8.4285,   5.9975,   5.1286,  -1.6673,\n",
            "           0.7746,   2.9898, -15.6718],\n",
            "        [  5.8769,  14.0695,  -9.3457,  -3.6894,  -9.0683,  -5.7154,   1.4076,\n",
            "          -3.7431,   0.1884,   3.5082],\n",
            "        [  0.9250,  -7.1394,   1.2859,  -5.8900,  -2.5742,   6.0436,  -2.1926,\n",
            "          -4.6113,  -4.9391,  -8.3861],\n",
            "        [ -2.7889,  -2.9515,  -7.7820,  -5.0301,   1.5879,   8.1158,   6.8313,\n",
            "           5.9296,  -0.9705,  -2.5105],\n",
            "        [  2.5664,   9.4434,  -5.8846,  -0.3154,   4.5435,   1.8058,   4.9068,\n",
            "          -6.2827,  -3.3517,  -0.1978],\n",
            "        [  1.7198,  -2.2071,  -0.1362,   6.6191,   3.8913,  -8.2752,  -6.8544,\n",
            "           4.2479,  -9.0866,  -4.8929],\n",
            "        [  4.7103, -11.4880,  -4.0422,   6.2474,  -4.1584,   1.0862,   3.6538,\n",
            "          -8.9554,  -2.6485,   0.7573],\n",
            "        [ -4.9369,   6.5344,   3.1946,   8.3981,  -3.5897,  -9.2027,  12.5718,\n",
            "          -3.0551, -10.8233,   1.7797]], device='cuda:0')\n",
            "\n",
            "Conv Outputs ^^\n",
            "\n",
            "==========\n",
            "Notice how the function is applied element-wise!\n",
            "==========\n",
            "\n",
            "After Activation \n",
            "\n",
            "tensor([[ 0.0000,  4.0931,  2.7057,  0.0000,  8.3933,  0.3624,  4.4993,  0.0000,\n",
            "          0.0000,  3.8652],\n",
            "        [ 0.0000,  8.9368,  5.4750,  0.8334,  2.5965, 10.3463,  0.0000,  0.0000,\n",
            "         17.8576,  0.0000],\n",
            "        [ 0.0597,  0.0000,  4.4270,  0.0000,  5.9975,  5.1286,  0.0000,  0.7746,\n",
            "          2.9898,  0.0000],\n",
            "        [ 5.8769, 14.0695,  0.0000,  0.0000,  0.0000,  0.0000,  1.4076,  0.0000,\n",
            "          0.1884,  3.5082],\n",
            "        [ 0.9250,  0.0000,  1.2859,  0.0000,  0.0000,  6.0436,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.5879,  8.1158,  6.8313,  5.9296,\n",
            "          0.0000,  0.0000],\n",
            "        [ 2.5664,  9.4434,  0.0000,  0.0000,  4.5435,  1.8058,  4.9068,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 1.7198,  0.0000,  0.0000,  6.6191,  3.8913,  0.0000,  0.0000,  4.2479,\n",
            "          0.0000,  0.0000],\n",
            "        [ 4.7103,  0.0000,  0.0000,  6.2474,  0.0000,  1.0862,  3.6538,  0.0000,\n",
            "          0.0000,  0.7573],\n",
            "        [ 0.0000,  6.5344,  3.1946,  8.3981,  0.0000,  0.0000, 12.5718,  0.0000,\n",
            "          0.0000,  1.7797]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling\n"
      ],
      "metadata": {
        "id": "4s69QNoS4dsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_pooling(z,pool_size):\n",
        "  feautre_count,h,w = z.shape\n",
        "\n",
        "  pool_height,pool_width = pool_size\n",
        "  # print(f\"h={h} , pool_h = {pool_height}\")\n",
        "  # print(f\"w={w} , pool_w = {pool_width}\")\n",
        "  assert(h % pool_height == 0)\n",
        "  assert(w % pool_width == 0)\n",
        "\n",
        "  out_h = h // pool_height\n",
        "  out_w = w // pool_width\n",
        "\n",
        "  out = torch.zeros((feautre_count,out_h,out_w),device=device)\n",
        "\n",
        "  for  i in range(out_h):\n",
        "    for j in range(out_w):\n",
        "      patch_to_pool = z[:,i*pool_height,j*pool_width]\n",
        "      pooled = torch.max(patch_to_pool)\n",
        "      out[:,i,j] = pooled\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "7M4t6fyZ4flP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets test this\n",
        "\n",
        "out = conv2d_like_torch(x, w, b)\n",
        "print(out.shape)\n",
        "z = F.relu(out)\n",
        "print(z.shape)\n",
        "# === POOLING ===\n",
        "out_pool = do_pooling(z,pool_size=(2,2))\n",
        "print(out_pool.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaPouVdA6ZE7",
        "outputId": "d41f01ff-1dcf-4ff9-cf02-81b9b41df0c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 10, 10])\n",
            "torch.Size([6, 10, 10])\n",
            "torch.Size([6, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome we can see that the output of the activation `z` of shape (6,10,10) was pooled down to (6,5,5) by a pooling filter of 2x2 :)\n"
      ],
      "metadata": {
        "id": "UNHi6opm8ItD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it all together!"
      ],
      "metadata": {
        "id": "QpESrUe48W7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets say we have inputs of size 28x28 which are images we need to classify into some target labels. How can we use a CNN to learn this? Lets design a network using our functions !"
      ],
      "metadata": {
        "id": "xLwhOpIV8upG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Model Params"
      ],
      "metadata": {
        "id": "JR1895d7KA7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a filter bank\n",
        "conv_W1 = torch.randn((6,1,4,4) , requires_grad=True,device=device) # 6 filters , 1 channel each of 3x3 width_x_height\n",
        "conv_b1 = torch.zeros(6, requires_grad=True,device=device)\n",
        "\n",
        "# Weights for linear layer\n",
        "W1 = torch.randn(10,6*1*5*5, requires_grad=True, device=device)\n",
        "# Explaination for the shape , look at the last conv layer\n",
        "# 6 filters\n",
        "# 1 channel\n",
        "# 25 steps for a width 4 filter to cover input width 28 @ stride 1\n",
        "# 25 steps for a height 4 filter to cover input height 28 @ stride 1\n",
        "# 6 * 1 * 25 * 25\n",
        "# Then we do pooling with a 5x5 filter which converts it to :\n",
        "# 6 * 1 * 5 * 5\n",
        "# So will have a weight matrix of size (150,10) , 10 since we have to output classes in the prediction space.\n",
        "b1 = torch.zeros(10, requires_grad=True, device=device)\n",
        "\n",
        "print(f\"conv_W1 shape is {conv_W1.shape}\")\n",
        "print(f\"conv_b1 shape is {conv_b1.shape}\")\n",
        "print(f\"W1 shape is {W1.shape}\")\n",
        "print(f\"b1 shape is {b1.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7eg0vUB8mj1",
        "outputId": "a04d1923-1a08-4d38-8c4a-3f316ae10e71"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_W1 shape is torch.Size([6, 1, 4, 4])\n",
            "conv_b1 shape is torch.Size([6])\n",
            "W1 shape is torch.Size([10, 150])\n",
            "b1 shape is torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Loss Function and Optimizer**"
      ],
      "metadata": {
        "id": "87R4a15HKt_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Loss Fn and Optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optm = torch.optim.Adam(params=[conv_W1,conv_b1,W1,b1],lr=0.01)"
      ],
      "metadata": {
        "id": "si_5tLm69ZV2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a forward pass**\n",
        "\n",
        "\n",
        "Think of the conv step as \"feature\" extractors and the linear layer like the predictors which learn from the extacted features."
      ],
      "metadata": {
        "id": "Q_sSZMSeKyjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(x):\n",
        "  # print(x.device)\n",
        "  o = conv2d_like_torch(x,conv_W1,conv_b1)\n",
        "  # print(f\"training: input {x.shape} -- conv2d --> {o.shape} | {o.device}\")\n",
        "  z = F.relu(o)\n",
        "  p = do_pooling(z,(5,5))\n",
        "  # print(f\"training: pooling {z.shape} -- pool --> {p.shape} | {p.device}\")\n",
        "  # This is the conv part , we still need a linear part to make predictions\n",
        "  flat = p.flatten().to(device)\n",
        "  # print(f\"training: {p.shape} -- flattened to --> {flat.shape}\")\n",
        "  logits = F.linear(flat,W1,b1)\n",
        "  # print(f\"training: logits shape is {logits.shape}\")\n",
        "  # Finally we will use a softmax on the logits to create a probability distribusion of the prediction across all possible classes( 1 to 10)\n",
        "  preds = F.softmax(logits,dim=0)\n",
        "  # print(f\"training: preds shape is {preds.shape}\")\n",
        "  return preds\n",
        ""
      ],
      "metadata": {
        "id": "1--bDPNm9nMP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "random_data = torch.randn((1,28,28),device=device)\n",
        "# Ensure forward_pass_2 returns logits, which is what it does now.\n",
        "# For a sanity check, we might want to see the logits or apply softmax for interpretation.\n",
        "logits_output = forward_pass(random_data)\n",
        "print(f\"Logits output shape: {logits_output.shape}\")\n",
        "# If you want to see probabilities, apply softmax here (but not in the forward_pass_2 itself for training with CrossEntropyLoss)\n",
        "preds_output = F.softmax(logits_output, dim=0)\n",
        "print(f\"Probabilities output (after softmax): {preds_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpLPvm0BCXET",
        "outputId": "31c7e54b-3b4b-4577-a393-c53c0cf17661"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits output shape: torch.Size([10])\n",
            "Probabilities output (after softmax): tensor([0.0856, 0.0856, 0.0856, 0.0856, 0.0856, 0.2283, 0.0856, 0.0856, 0.0856,\n",
            "        0.0872], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward pass work ✅\n",
        "\n",
        "Lets write a training loop"
      ],
      "metadata": {
        "id": "88DZA5qJJ5-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tNgItbvgUVai"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_train: torch.tensor, y_train):\n",
        "  loss_history = []\n",
        "  for e in range(epochs):\n",
        "    count = x_train.shape[0]\n",
        "    tqdm_iter = tqdm(range(count))\n",
        "    for i in tqdm_iter:\n",
        "      inp = x_train[i]\n",
        "      preds = forward_pass(inp if inp.shape == (1,28,28) else inp.reshape(1,28,28))\n",
        "      loss = loss_fn(preds,y_train[i])\n",
        "      optm.zero_grad()\n",
        "      loss.backward()\n",
        "      optm.step()\n",
        "      tqdm_iter.set_description(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
        "    print(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
        "    loss_history.append(loss.item())\n",
        "  return loss_history"
      ],
      "metadata": {
        "id": "YNnQDHdLJ-Wl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup a dataset: MNIST\n",
        "\n",
        "Using https://docs.pytorch.org/tutorials/beginner/nn_tutorial.html#mnist-data-setup"
      ],
      "metadata": {
        "id": "Jm4FP3AJLaue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)\n",
        "\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "# ``pyplot.show()`` only if not on Colab\n",
        "try:\n",
        "    import google.colab\n",
        "except ImportError:\n",
        "    pyplot.show()\n",
        "print(x_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "id": "XYyHdZ0iLafg",
        "outputId": "1e99c4ce-29f7-4898-d44e-7f53b5e19c86"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aajf6KcMLqG_",
        "outputId": "7dc77b0c-8dd7-458e-88b6-88e470aceacd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-_F65joMSG-",
        "outputId": "30f6c139-7045-4543-c0e5-cb809081aa34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Time!\n"
      ],
      "metadata": {
        "id": "ed13drYGOG0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.from_numpy(x_train).float().reshape(-1, 1, 28, 28).to(device)\n",
        "# y_train needs to be integer labels for CrossEntropyLoss\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "\n",
        "print(x_train_tensor.shape , x_train_tensor.device)\n",
        "print(y_train_tensor.shape, y_train_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWAMx5SeMVBL",
        "outputId": "6d4b83d9-0896-4b0e-9772-2b36e56b4353"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000, 1, 28, 28]) cuda:0\n",
            "torch.Size([50000]) cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # loss_hist = train(x_train_tensor[:10], y_train_one_hot[:10])"
      ],
      "metadata": {
        "id": "A_1SRs8DOkh3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well while this works, its ridiculously slow! its as if using a GPU here is almost making no difference, why is that? thats cause we are using a triple loop in out conv2d operation, and GPUs hate loops!\n",
        "\n",
        "### Vectorizing Ops\n",
        "Lets explore the \"unfold\" op on torch which will help us speed things up"
      ],
      "metadata": {
        "id": "js4-lH_2Yzkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_train_tensor[:10]\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi8Fb1JKYC6H",
        "outputId": "af4bc30f-9df5-4ccf-b9b1-7c90751ce9e2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = F.unfold(x,kernel_size=(4,4),stride=1)\n",
        "print(r.shape)\n",
        "# torch.Size([10, 16, 625])\n",
        "# 10 = no of samples\n",
        "# 16 is the flattened size of the patch we wish to create\n",
        "# 625 is the flattened size of the conv operation on a single sample\n",
        "\n",
        "\"\"\"\n",
        "What unfold really does is flattens the spatial dims while leaving the batch and channel dims unchanged.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zvHALOq9dGN1",
        "outputId": "3ffef584-c3e8-406f-98f5-7bdd9291de5d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 16, 625])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWhat unfold really does is flattens the spatial dims while leaving the batch and channel dims unchanged.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_unfold_batch(x, w, b=None):\n",
        "    # x: (batch,C_in, H, W)  !!! CHANGE !!!\n",
        "    # w: (C_out, C_in, KH, KW)\n",
        "    batch,C_in, H, W_ = x.shape\n",
        "    C_out, C_in_w, KH, KW = w.shape\n",
        "    assert C_in == C_in_w\n",
        "\n",
        "    # (C_in*KH*KW, out_h*out_w)\n",
        "    cols = torch.nn.functional.unfold(x, kernel_size=(KH, KW))  # (C_in*KH*KW, L)\n",
        "\n",
        "    w_flat = w.view(C_out, -1)                                               # (C_out, Ck)\n",
        "\n",
        "    # Note that conv originally implemeted a element-wise multiply and sum()\n",
        "    # the same is done when we do the below dot product with @ since cols and\n",
        "    # w_flat are setup as above.\n",
        "    out = (w_flat @ cols)                                                    # (C_out, L)\n",
        "\n",
        "    out_h = H - KH + 1\n",
        "    out_w = W_ - KW + 1\n",
        "    out = out.view(batch,C_out, out_h, out_w)\n",
        "\n",
        "    if b is not None:\n",
        "        out = out + b.view(-1, 1, 1)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "BobAahK7jhyI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "N, C_in, H, W = 32, 3, 12, 12\n",
        "C_out, KH, KW = 5, 3, 3\n",
        "\n",
        "X = torch.randn(N, C_in, H, W, device=\"cuda\")\n",
        "W = torch.randn(C_out, C_in, KH, KW, device=\"cuda\")\n",
        "b = torch.randn(C_out, device=\"cuda\")\n",
        "\n",
        "y1 = conv2d_unfold_batch(X, W, b)\n",
        "y2 = F.conv2d(X, W, b)\n",
        "\n",
        "# low diff indicates our implementation is close to how torch does it internally!\n",
        "print((y1 - y2).abs().max())\n",
        "print(y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "DgbWO4af74yv",
        "outputId": "cbe4a485-8914-498f-eeef-10026f54dadc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.7684e-06, device='cuda:0')\n",
            "torch.Size([32, 5, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_pooling(x,pool_size):\n",
        "  # print(x.shape)\n",
        "  batch,feautre_count,h,w = x.shape\n",
        "  # print(f\"x shape = {x.shape}\")\n",
        "  pool_height,pool_width = pool_size\n",
        "\n",
        "  # since we are not padding and have fixed striding of pool_size\n",
        "  assert(h % pool_height == 0)\n",
        "  assert(w % pool_width == 0)\n",
        "\n",
        "  out_h = h // pool_height\n",
        "  out_w = w // pool_width\n",
        "\n",
        "  # This should create a tensor of shape (batch, ft_count * h * w)\n",
        "  cols = F.unfold(x,kernel_size=pool_size,stride=pool_size)\n",
        "  # print(f\"Shape after unfolding for pool is {cols.shape}\")\n",
        "  cols = cols.view(batch,feautre_count, (pool_height * pool_width), -1)\n",
        "  # print(f\"Shape after unfolding-RESHAPE for pool is {cols.shape}\")\n",
        "\n",
        "  max_pooled = cols.max(dim=2).values\n",
        "  res = max_pooled.view(batch,feautre_count,out_h,out_w)\n",
        "  # print(f\"Shape after pooling is {res.shape}\")\n",
        "  return res"
      ],
      "metadata": {
        "id": "mnlzOezWCe_w"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "my_p = batch_pooling(y1,(2,2))\n",
        "torch_p = F.max_pool2d(y1,(2,2))\n",
        "print(my_p.shape)\n",
        "print(torch_p.shape)\n",
        "# compare values\n",
        "print(torch.max(torch.abs(my_p - torch_p)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-v6dkUWEIcbd",
        "outputId": "5e0294eb-c7c0-4280-955a-14950bf8c56a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5, 5, 5])\n",
            "torch.Size([32, 5, 5, 5])\n",
            "tensor(0., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass_2(x_batch):\n",
        "  # print(x.device)\n",
        "  o = conv2d_unfold_batch(x_batch,conv_W1,conv_b1)\n",
        "  # print(f\"training: input {x.shape} -- conv2d --> {o.shape} | {o.device}\")\n",
        "  z = F.relu(o)\n",
        "  p = batch_pooling(z,torch.tensor((5,5))) # !!! CHANGED !!!\n",
        "  # print(f\"training: pooling {z.shape} -- pool --> {p.shape} | {p.device}\")\n",
        "  # This is the conv part , we still need a linear part to make predictions\n",
        "  flat = p.flatten(start_dim=1).to(device) # avoid falttening the batch dim\n",
        "  # print(f\"training: {p.shape} -- flattened to --> {flat.shape}\")\n",
        "  logits = F.linear(flat,W1,b1)\n",
        "  # print(f\"training: logits shape is {logits.shape}\")\n",
        "  # For CrossEntropyLoss, we return raw logits. Softmax is applied externally for prediction.\n",
        "  # preds = F.softmax(logits,dim=1)\n",
        "  # print(f\"training: preds shape is {preds.shape}\")\n",
        "  return logits"
      ],
      "metadata": {
        "id": "zOoMcU8rjnHJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2(x_train: torch.tensor, y_train,batch_size = 128):\n",
        "  loss_history = []\n",
        "  for e in range(epochs):\n",
        "    count = x_train.shape[0]\n",
        "    tqdm_iter = tqdm(range(0,count,batch_size))\n",
        "    for i in tqdm_iter:\n",
        "      inp = x_train[i:i+batch_size]\n",
        "      preds = forward_pass_2(inp) # preds are now logits\n",
        "      target = y_train[i: i+batch_size] # target are integer labels\n",
        "      # print(f\"preds {preds.shape}\\n targets: {target.shape}\")\n",
        "      loss = loss_fn(preds,target)\n",
        "      optm.zero_grad()\n",
        "      loss.backward()\n",
        "      optm.step()\n",
        "      tqdm_iter.set_description(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
        "    # print(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
        "    loss_history.append(loss.item())\n",
        "  return loss_history"
      ],
      "metadata": {
        "id": "CnxLP9IXjq3J"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_hist = train_2(x_train_tensor[:10], y_train_tensor[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld3EMT4PjxxB",
        "outputId": "2b588f7c-cce7-4e22-872f-f2ec70cde57d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0, Loss: 27.036285400390625: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
            "Epoch: 1, Loss: 24.813064575195312: 100%|██████████| 1/1 [00:00<00:00, 302.49it/s]\n",
            "Epoch: 2, Loss: 22.870214462280273: 100%|██████████| 1/1 [00:00<00:00, 333.70it/s]\n",
            "Epoch: 3, Loss: 21.115123748779297: 100%|██████████| 1/1 [00:00<00:00, 376.10it/s]\n",
            "Epoch: 4, Loss: 19.44328498840332: 100%|██████████| 1/1 [00:00<00:00, 306.04it/s]\n",
            "Epoch: 5, Loss: 17.86960220336914: 100%|██████████| 1/1 [00:00<00:00, 387.89it/s]\n",
            "Epoch: 6, Loss: 16.488168716430664: 100%|██████████| 1/1 [00:00<00:00, 385.40it/s]\n",
            "Epoch: 7, Loss: 15.279156684875488: 100%|██████████| 1/1 [00:00<00:00, 378.48it/s]\n",
            "Epoch: 8, Loss: 14.25286865234375: 100%|██████████| 1/1 [00:00<00:00, 370.26it/s]\n",
            "Epoch: 9, Loss: 13.370794296264648: 100%|██████████| 1/1 [00:00<00:00, 396.70it/s]\n",
            "Epoch: 10, Loss: 12.547201156616211: 100%|██████████| 1/1 [00:00<00:00, 407.93it/s]\n",
            "Epoch: 11, Loss: 11.757967948913574: 100%|██████████| 1/1 [00:00<00:00, 353.09it/s]\n",
            "Epoch: 12, Loss: 11.002798080444336: 100%|██████████| 1/1 [00:00<00:00, 402.79it/s]\n",
            "Epoch: 13, Loss: 10.287678718566895: 100%|██████████| 1/1 [00:00<00:00, 397.90it/s]\n",
            "Epoch: 14, Loss: 9.599589347839355: 100%|██████████| 1/1 [00:00<00:00, 404.97it/s]\n",
            "Epoch: 15, Loss: 8.9050874710083: 100%|██████████| 1/1 [00:00<00:00, 397.41it/s]\n",
            "Epoch: 16, Loss: 8.207797050476074: 100%|██████████| 1/1 [00:00<00:00, 411.65it/s]\n",
            "Epoch: 17, Loss: 7.5226240158081055: 100%|██████████| 1/1 [00:00<00:00, 401.06it/s]\n",
            "Epoch: 18, Loss: 6.8577880859375: 100%|██████████| 1/1 [00:00<00:00, 415.03it/s]\n",
            "Epoch: 19, Loss: 6.2154130935668945: 100%|██████████| 1/1 [00:00<00:00, 414.13it/s]\n",
            "Epoch: 20, Loss: 5.60671329498291: 100%|██████████| 1/1 [00:00<00:00, 402.18it/s]\n",
            "Epoch: 21, Loss: 5.045195579528809: 100%|██████████| 1/1 [00:00<00:00, 406.90it/s]\n",
            "Epoch: 22, Loss: 4.546123504638672: 100%|██████████| 1/1 [00:00<00:00, 320.89it/s]\n",
            "Epoch: 23, Loss: 4.091818809509277: 100%|██████████| 1/1 [00:00<00:00, 347.21it/s]\n",
            "Epoch: 24, Loss: 3.663243055343628: 100%|██████████| 1/1 [00:00<00:00, 375.80it/s]\n",
            "Epoch: 25, Loss: 3.2471656799316406: 100%|██████████| 1/1 [00:00<00:00, 367.31it/s]\n",
            "Epoch: 26, Loss: 2.835813522338867: 100%|██████████| 1/1 [00:00<00:00, 354.16it/s]\n",
            "Epoch: 27, Loss: 2.445590019226074: 100%|██████████| 1/1 [00:00<00:00, 388.07it/s]\n",
            "Epoch: 28, Loss: 2.0803518295288086: 100%|██████████| 1/1 [00:00<00:00, 384.94it/s]\n",
            "Epoch: 29, Loss: 1.7591098546981812: 100%|██████████| 1/1 [00:00<00:00, 405.01it/s]\n",
            "Epoch: 30, Loss: 1.4754364490509033: 100%|██████████| 1/1 [00:00<00:00, 417.43it/s]\n",
            "Epoch: 31, Loss: 1.22762930393219: 100%|██████████| 1/1 [00:00<00:00, 416.97it/s]\n",
            "Epoch: 32, Loss: 1.007664442062378: 100%|██████████| 1/1 [00:00<00:00, 414.58it/s]\n",
            "Epoch: 33, Loss: 0.8095401525497437: 100%|██████████| 1/1 [00:00<00:00, 413.44it/s]\n",
            "Epoch: 34, Loss: 0.6380318999290466: 100%|██████████| 1/1 [00:00<00:00, 402.29it/s]\n",
            "Epoch: 35, Loss: 0.5016689300537109: 100%|██████████| 1/1 [00:00<00:00, 338.14it/s]\n",
            "Epoch: 36, Loss: 0.3985580801963806: 100%|██████████| 1/1 [00:00<00:00, 393.24it/s]\n",
            "Epoch: 37, Loss: 0.3213265538215637: 100%|██████████| 1/1 [00:00<00:00, 399.19it/s]\n",
            "Epoch: 38, Loss: 0.2629360854625702: 100%|██████████| 1/1 [00:00<00:00, 323.01it/s]\n",
            "Epoch: 39, Loss: 0.21891137957572937: 100%|██████████| 1/1 [00:00<00:00, 343.49it/s]\n",
            "Epoch: 40, Loss: 0.18460051715373993: 100%|██████████| 1/1 [00:00<00:00, 367.02it/s]\n",
            "Epoch: 41, Loss: 0.15752148628234863: 100%|██████████| 1/1 [00:00<00:00, 353.17it/s]\n",
            "Epoch: 42, Loss: 0.1365569829940796: 100%|██████████| 1/1 [00:00<00:00, 368.83it/s]\n",
            "Epoch: 43, Loss: 0.11976532638072968: 100%|██████████| 1/1 [00:00<00:00, 400.07it/s]\n",
            "Epoch: 44, Loss: 0.10669294744729996: 100%|██████████| 1/1 [00:00<00:00, 393.39it/s]\n",
            "Epoch: 45, Loss: 0.09674485772848129: 100%|██████████| 1/1 [00:00<00:00, 398.62it/s]\n",
            "Epoch: 46, Loss: 0.08829016983509064: 100%|██████████| 1/1 [00:00<00:00, 394.83it/s]\n",
            "Epoch: 47, Loss: 0.08037517219781876: 100%|██████████| 1/1 [00:00<00:00, 378.86it/s]\n",
            "Epoch: 48, Loss: 0.0727725550532341: 100%|██████████| 1/1 [00:00<00:00, 402.25it/s]\n",
            "Epoch: 49, Loss: 0.06564654409885406: 100%|██████████| 1/1 [00:00<00:00, 382.41it/s]\n",
            "Epoch: 50, Loss: 0.05907542258501053: 100%|██████████| 1/1 [00:00<00:00, 320.81it/s]\n",
            "Epoch: 51, Loss: 0.05318284034729004: 100%|██████████| 1/1 [00:00<00:00, 345.47it/s]\n",
            "Epoch: 52, Loss: 0.04794832319021225: 100%|██████████| 1/1 [00:00<00:00, 315.15it/s]\n",
            "Epoch: 53, Loss: 0.043419379740953445: 100%|██████████| 1/1 [00:00<00:00, 357.45it/s]\n",
            "Epoch: 54, Loss: 0.03959538787603378: 100%|██████████| 1/1 [00:00<00:00, 350.96it/s]\n",
            "Epoch: 55, Loss: 0.03629555553197861: 100%|██████████| 1/1 [00:00<00:00, 371.74it/s]\n",
            "Epoch: 56, Loss: 0.03342572599649429: 100%|██████████| 1/1 [00:00<00:00, 387.36it/s]\n",
            "Epoch: 57, Loss: 0.030915727838873863: 100%|██████████| 1/1 [00:00<00:00, 372.10it/s]\n",
            "Epoch: 58, Loss: 0.028729135170578957: 100%|██████████| 1/1 [00:00<00:00, 351.43it/s]\n",
            "Epoch: 59, Loss: 0.026816552504897118: 100%|██████████| 1/1 [00:00<00:00, 392.25it/s]\n",
            "Epoch: 60, Loss: 0.02513146959245205: 100%|██████████| 1/1 [00:00<00:00, 347.15it/s]\n",
            "Epoch: 61, Loss: 0.023639976978302002: 100%|██████████| 1/1 [00:00<00:00, 359.07it/s]\n",
            "Epoch: 62, Loss: 0.022307809442281723: 100%|██████████| 1/1 [00:00<00:00, 330.62it/s]\n",
            "Epoch: 63, Loss: 0.02111368253827095: 100%|██████████| 1/1 [00:00<00:00, 369.74it/s]\n",
            "Epoch: 64, Loss: 0.020039794966578484: 100%|██████████| 1/1 [00:00<00:00, 356.81it/s]\n",
            "Epoch: 65, Loss: 0.019070763140916824: 100%|██████████| 1/1 [00:00<00:00, 359.81it/s]\n",
            "Epoch: 66, Loss: 0.01819075644016266: 100%|██████████| 1/1 [00:00<00:00, 370.95it/s]\n",
            "Epoch: 67, Loss: 0.017387650907039642: 100%|██████████| 1/1 [00:00<00:00, 364.75it/s]\n",
            "Epoch: 68, Loss: 0.0166454017162323: 100%|██████████| 1/1 [00:00<00:00, 375.09it/s]\n",
            "Epoch: 69, Loss: 0.015986595302820206: 100%|██████████| 1/1 [00:00<00:00, 378.75it/s]\n",
            "Epoch: 70, Loss: 0.01537701953202486: 100%|██████████| 1/1 [00:00<00:00, 379.85it/s]\n",
            "Epoch: 71, Loss: 0.01481219194829464: 100%|██████████| 1/1 [00:00<00:00, 356.99it/s]\n",
            "Epoch: 72, Loss: 0.014288228936493397: 100%|██████████| 1/1 [00:00<00:00, 351.72it/s]\n",
            "Epoch: 73, Loss: 0.01380098145455122: 100%|██████████| 1/1 [00:00<00:00, 364.72it/s]\n",
            "Epoch: 74, Loss: 0.013346550054848194: 100%|██████████| 1/1 [00:00<00:00, 377.25it/s]\n",
            "Epoch: 75, Loss: 0.012922093272209167: 100%|██████████| 1/1 [00:00<00:00, 345.81it/s]\n",
            "Epoch: 76, Loss: 0.012525618076324463: 100%|██████████| 1/1 [00:00<00:00, 344.42it/s]\n",
            "Epoch: 77, Loss: 0.012157107703387737: 100%|██████████| 1/1 [00:00<00:00, 349.38it/s]\n",
            "Epoch: 78, Loss: 0.011818476021289825: 100%|██████████| 1/1 [00:00<00:00, 400.87it/s]\n",
            "Epoch: 79, Loss: 0.01150166429579258: 100%|██████████| 1/1 [00:00<00:00, 364.15it/s]\n",
            "Epoch: 80, Loss: 0.011204227805137634: 100%|██████████| 1/1 [00:00<00:00, 355.39it/s]\n",
            "Epoch: 81, Loss: 0.01092469971626997: 100%|██████████| 1/1 [00:00<00:00, 353.00it/s]\n",
            "Epoch: 82, Loss: 0.01066194660961628: 100%|██████████| 1/1 [00:00<00:00, 353.09it/s]\n",
            "Epoch: 83, Loss: 0.010415562428534031: 100%|██████████| 1/1 [00:00<00:00, 369.28it/s]\n",
            "Epoch: 84, Loss: 0.010183225385844707: 100%|██████████| 1/1 [00:00<00:00, 372.86it/s]\n",
            "Epoch: 85, Loss: 0.00996394269168377: 100%|██████████| 1/1 [00:00<00:00, 362.61it/s]\n",
            "Epoch: 86, Loss: 0.009756280109286308: 100%|██████████| 1/1 [00:00<00:00, 376.20it/s]\n",
            "Epoch: 87, Loss: 0.009559759870171547: 100%|██████████| 1/1 [00:00<00:00, 373.06it/s]\n",
            "Epoch: 88, Loss: 0.009373648092150688: 100%|██████████| 1/1 [00:00<00:00, 386.79it/s]\n",
            "Epoch: 89, Loss: 0.009197866544127464: 100%|██████████| 1/1 [00:00<00:00, 350.87it/s]\n",
            "Epoch: 90, Loss: 0.009031514637172222: 100%|██████████| 1/1 [00:00<00:00, 376.71it/s]\n",
            "Epoch: 91, Loss: 0.008873811922967434: 100%|██████████| 1/1 [00:00<00:00, 395.09it/s]\n",
            "Epoch: 92, Loss: 0.00872349925339222: 100%|██████████| 1/1 [00:00<00:00, 384.02it/s]\n",
            "Epoch: 93, Loss: 0.008580075576901436: 100%|██████████| 1/1 [00:00<00:00, 357.33it/s]\n",
            "Epoch: 94, Loss: 0.008443063125014305: 100%|██████████| 1/1 [00:00<00:00, 363.62it/s]\n",
            "Epoch: 95, Loss: 0.008311934769153595: 100%|██████████| 1/1 [00:00<00:00, 361.98it/s]\n",
            "Epoch: 96, Loss: 0.00818636454641819: 100%|██████████| 1/1 [00:00<00:00, 373.19it/s]\n",
            "Epoch: 97, Loss: 0.00806545838713646: 100%|██████████| 1/1 [00:00<00:00, 355.54it/s]\n",
            "Epoch: 98, Loss: 0.007947585545480251: 100%|██████████| 1/1 [00:00<00:00, 360.06it/s]\n",
            "Epoch: 99, Loss: 0.007834041491150856: 100%|██████████| 1/1 [00:00<00:00, 336.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FASTTT! Now lets train the network with the full training dataset!"
      ],
      "metadata": {
        "id": "7AsKi4W9z8xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_hist = train_2(x_train_tensor, y_train_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxqvtcgWz8hC",
        "outputId": "74bfbcd5-f7fc-4af0-f2f5-3e20a31fce4d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0, Loss: 0.6496384143829346: 100%|██████████| 391/391 [00:01<00:00, 270.79it/s]\n",
            "Epoch: 1, Loss: 0.3296597898006439: 100%|██████████| 391/391 [00:01<00:00, 280.31it/s]\n",
            "Epoch: 2, Loss: 0.15230874717235565: 100%|██████████| 391/391 [00:01<00:00, 280.40it/s]\n",
            "Epoch: 3, Loss: 0.09111916273832321: 100%|██████████| 391/391 [00:01<00:00, 270.09it/s]\n",
            "Epoch: 4, Loss: 0.06426788866519928: 100%|██████████| 391/391 [00:01<00:00, 278.62it/s]\n",
            "Epoch: 5, Loss: 0.05342394858598709: 100%|██████████| 391/391 [00:01<00:00, 283.01it/s]\n",
            "Epoch: 6, Loss: 0.046611540019512177: 100%|██████████| 391/391 [00:01<00:00, 276.31it/s]\n",
            "Epoch: 7, Loss: 0.040265344083309174: 100%|██████████| 391/391 [00:01<00:00, 275.26it/s]\n",
            "Epoch: 8, Loss: 0.037286363542079926: 100%|██████████| 391/391 [00:01<00:00, 275.32it/s]\n",
            "Epoch: 9, Loss: 0.03542846441268921: 100%|██████████| 391/391 [00:01<00:00, 278.42it/s]\n",
            "Epoch: 10, Loss: 0.03272293135523796: 100%|██████████| 391/391 [00:01<00:00, 273.00it/s]\n",
            "Epoch: 11, Loss: 0.031592875719070435: 100%|██████████| 391/391 [00:01<00:00, 269.82it/s]\n",
            "Epoch: 12, Loss: 0.029441798105835915: 100%|██████████| 391/391 [00:01<00:00, 273.98it/s]\n",
            "Epoch: 13, Loss: 0.02702547051012516: 100%|██████████| 391/391 [00:01<00:00, 276.95it/s]\n",
            "Epoch: 14, Loss: 0.025397490710020065: 100%|██████████| 391/391 [00:01<00:00, 275.00it/s]\n",
            "Epoch: 15, Loss: 0.023885376751422882: 100%|██████████| 391/391 [00:01<00:00, 273.95it/s]\n",
            "Epoch: 16, Loss: 0.02433016337454319: 100%|██████████| 391/391 [00:01<00:00, 278.97it/s]\n",
            "Epoch: 17, Loss: 0.026045996695756912: 100%|██████████| 391/391 [00:01<00:00, 275.37it/s]\n",
            "Epoch: 18, Loss: 0.026095908135175705: 100%|██████████| 391/391 [00:01<00:00, 269.79it/s]\n",
            "Epoch: 19, Loss: 0.02747800573706627: 100%|██████████| 391/391 [00:01<00:00, 267.24it/s]\n",
            "Epoch: 20, Loss: 0.026153746992349625: 100%|██████████| 391/391 [00:01<00:00, 276.20it/s]\n",
            "Epoch: 21, Loss: 0.026796290650963783: 100%|██████████| 391/391 [00:01<00:00, 278.09it/s]\n",
            "Epoch: 22, Loss: 0.0290546752512455: 100%|██████████| 391/391 [00:01<00:00, 279.26it/s]\n",
            "Epoch: 23, Loss: 0.030144870281219482: 100%|██████████| 391/391 [00:01<00:00, 277.17it/s]\n",
            "Epoch: 24, Loss: 0.030757978558540344: 100%|██████████| 391/391 [00:01<00:00, 276.54it/s]\n",
            "Epoch: 25, Loss: 0.03128697723150253: 100%|██████████| 391/391 [00:01<00:00, 276.71it/s]\n",
            "Epoch: 26, Loss: 0.030330907553434372: 100%|██████████| 391/391 [00:01<00:00, 277.27it/s]\n",
            "Epoch: 27, Loss: 0.0333702452480793: 100%|██████████| 391/391 [00:01<00:00, 277.08it/s]\n",
            "Epoch: 28, Loss: 0.03460806608200073: 100%|██████████| 391/391 [00:01<00:00, 269.16it/s]\n",
            "Epoch: 29, Loss: 0.035255324095487595: 100%|██████████| 391/391 [00:01<00:00, 277.15it/s]\n",
            "Epoch: 30, Loss: 0.031449321657419205: 100%|██████████| 391/391 [00:01<00:00, 272.30it/s]\n",
            "Epoch: 31, Loss: 0.033084437251091: 100%|██████████| 391/391 [00:01<00:00, 273.18it/s]\n",
            "Epoch: 32, Loss: 0.034443192183971405: 100%|██████████| 391/391 [00:01<00:00, 277.39it/s]\n",
            "Epoch: 33, Loss: 0.031228110194206238: 100%|██████████| 391/391 [00:01<00:00, 270.10it/s]\n",
            "Epoch: 34, Loss: 0.03163778781890869: 100%|██████████| 391/391 [00:01<00:00, 276.17it/s]\n",
            "Epoch: 35, Loss: 0.030853047966957092: 100%|██████████| 391/391 [00:01<00:00, 273.69it/s]\n",
            "Epoch: 36, Loss: 0.03282416611909866: 100%|██████████| 391/391 [00:01<00:00, 268.61it/s]\n",
            "Epoch: 37, Loss: 0.02999056503176689: 100%|██████████| 391/391 [00:01<00:00, 275.74it/s]\n",
            "Epoch: 38, Loss: 0.0309915654361248: 100%|██████████| 391/391 [00:01<00:00, 278.73it/s]\n",
            "Epoch: 39, Loss: 0.03172590583562851: 100%|██████████| 391/391 [00:01<00:00, 277.22it/s]\n",
            "Epoch: 40, Loss: 0.030121272429823875: 100%|██████████| 391/391 [00:01<00:00, 276.91it/s]\n",
            "Epoch: 41, Loss: 0.03429410606622696: 100%|██████████| 391/391 [00:01<00:00, 273.23it/s]\n",
            "Epoch: 42, Loss: 0.034895263612270355: 100%|██████████| 391/391 [00:01<00:00, 271.91it/s]\n",
            "Epoch: 43, Loss: 0.03958187252283096: 100%|██████████| 391/391 [00:01<00:00, 275.87it/s]\n",
            "Epoch: 44, Loss: 0.03915388137102127: 100%|██████████| 391/391 [00:01<00:00, 268.52it/s]\n",
            "Epoch: 45, Loss: 0.03887219354510307: 100%|██████████| 391/391 [00:01<00:00, 274.34it/s]\n",
            "Epoch: 46, Loss: 0.03830844908952713: 100%|██████████| 391/391 [00:01<00:00, 278.26it/s]\n",
            "Epoch: 47, Loss: 0.03862199932336807: 100%|██████████| 391/391 [00:01<00:00, 278.48it/s]\n",
            "Epoch: 48, Loss: 0.03802229091525078: 100%|██████████| 391/391 [00:01<00:00, 273.65it/s]\n",
            "Epoch: 49, Loss: 0.037917762994766235: 100%|██████████| 391/391 [00:01<00:00, 275.87it/s]\n",
            "Epoch: 50, Loss: 0.03691079840064049: 100%|██████████| 391/391 [00:01<00:00, 278.01it/s]\n",
            "Epoch: 51, Loss: 0.03532250225543976: 100%|██████████| 391/391 [00:01<00:00, 273.22it/s]\n",
            "Epoch: 52, Loss: 0.03780987486243248: 100%|██████████| 391/391 [00:01<00:00, 269.73it/s]\n",
            "Epoch: 53, Loss: 0.04089049622416496: 100%|██████████| 391/391 [00:01<00:00, 275.78it/s]\n",
            "Epoch: 54, Loss: 0.042333539575338364: 100%|██████████| 391/391 [00:01<00:00, 276.29it/s]\n",
            "Epoch: 55, Loss: 0.040161773562431335: 100%|██████████| 391/391 [00:01<00:00, 275.53it/s]\n",
            "Epoch: 56, Loss: 0.039970651268959045: 100%|██████████| 391/391 [00:01<00:00, 277.69it/s]\n",
            "Epoch: 57, Loss: 0.047256410121917725: 100%|██████████| 391/391 [00:01<00:00, 274.42it/s]\n",
            "Epoch: 58, Loss: 0.04919682815670967: 100%|██████████| 391/391 [00:01<00:00, 272.17it/s]\n",
            "Epoch: 59, Loss: 0.04872221127152443: 100%|██████████| 391/391 [00:01<00:00, 272.76it/s]\n",
            "Epoch: 60, Loss: 0.04318840056657791: 100%|██████████| 391/391 [00:01<00:00, 270.66it/s]\n",
            "Epoch: 61, Loss: 0.04799477010965347: 100%|██████████| 391/391 [00:01<00:00, 274.30it/s]\n",
            "Epoch: 62, Loss: 0.044889867305755615: 100%|██████████| 391/391 [00:01<00:00, 274.59it/s]\n",
            "Epoch: 63, Loss: 0.04797307401895523: 100%|██████████| 391/391 [00:01<00:00, 276.31it/s]\n",
            "Epoch: 64, Loss: 0.049915164709091187: 100%|██████████| 391/391 [00:01<00:00, 279.65it/s]\n",
            "Epoch: 65, Loss: 0.043852705508470535: 100%|██████████| 391/391 [00:01<00:00, 279.53it/s]\n",
            "Epoch: 66, Loss: 0.04850484058260918: 100%|██████████| 391/391 [00:01<00:00, 274.49it/s]\n",
            "Epoch: 67, Loss: 0.04811939597129822: 100%|██████████| 391/391 [00:01<00:00, 271.73it/s]\n",
            "Epoch: 68, Loss: 0.047456949949264526: 100%|██████████| 391/391 [00:01<00:00, 271.15it/s]\n",
            "Epoch: 69, Loss: 0.051326848566532135: 100%|██████████| 391/391 [00:01<00:00, 276.10it/s]\n",
            "Epoch: 70, Loss: 0.050203144550323486: 100%|██████████| 391/391 [00:01<00:00, 278.71it/s]\n",
            "Epoch: 71, Loss: 0.05012974888086319: 100%|██████████| 391/391 [00:01<00:00, 276.26it/s]\n",
            "Epoch: 72, Loss: 0.053727518767118454: 100%|██████████| 391/391 [00:01<00:00, 273.14it/s]\n",
            "Epoch: 73, Loss: 0.05082213878631592: 100%|██████████| 391/391 [00:01<00:00, 274.78it/s]\n",
            "Epoch: 74, Loss: 0.053372401744127274: 100%|██████████| 391/391 [00:01<00:00, 269.46it/s]\n",
            "Epoch: 75, Loss: 0.04772404953837395: 100%|██████████| 391/391 [00:01<00:00, 273.14it/s]\n",
            "Epoch: 76, Loss: 0.05124344676733017: 100%|██████████| 391/391 [00:01<00:00, 271.87it/s]\n",
            "Epoch: 77, Loss: 0.051718492060899734: 100%|██████████| 391/391 [00:01<00:00, 277.40it/s]\n",
            "Epoch: 78, Loss: 0.048045892268419266: 100%|██████████| 391/391 [00:01<00:00, 272.67it/s]\n",
            "Epoch: 79, Loss: 0.046297647058963776: 100%|██████████| 391/391 [00:01<00:00, 275.00it/s]\n",
            "Epoch: 80, Loss: 0.045244622975587845: 100%|██████████| 391/391 [00:01<00:00, 273.82it/s]\n",
            "Epoch: 81, Loss: 0.04746553301811218: 100%|██████████| 391/391 [00:01<00:00, 279.56it/s]\n",
            "Epoch: 82, Loss: 0.04776063188910484: 100%|██████████| 391/391 [00:01<00:00, 274.41it/s]\n",
            "Epoch: 83, Loss: 0.04707390069961548: 100%|██████████| 391/391 [00:01<00:00, 272.56it/s]\n",
            "Epoch: 84, Loss: 0.04264630004763603: 100%|██████████| 391/391 [00:01<00:00, 268.69it/s]\n",
            "Epoch: 85, Loss: 0.04644301161170006: 100%|██████████| 391/391 [00:01<00:00, 276.73it/s]\n",
            "Epoch: 86, Loss: 0.04669618234038353: 100%|██████████| 391/391 [00:01<00:00, 277.04it/s]\n",
            "Epoch: 87, Loss: 0.04132700338959694: 100%|██████████| 391/391 [00:01<00:00, 274.54it/s]\n",
            "Epoch: 88, Loss: 0.044973500072956085: 100%|██████████| 391/391 [00:01<00:00, 276.70it/s]\n",
            "Epoch: 89, Loss: 0.045403361320495605: 100%|██████████| 391/391 [00:01<00:00, 272.15it/s]\n",
            "Epoch: 90, Loss: 0.04404545575380325: 100%|██████████| 391/391 [00:01<00:00, 275.04it/s]\n",
            "Epoch: 91, Loss: 0.04612606763839722: 100%|██████████| 391/391 [00:01<00:00, 273.68it/s]\n",
            "Epoch: 92, Loss: 0.045406486839056015: 100%|██████████| 391/391 [00:01<00:00, 269.99it/s]\n",
            "Epoch: 93, Loss: 0.04544461891055107: 100%|██████████| 391/391 [00:01<00:00, 273.95it/s]\n",
            "Epoch: 94, Loss: 0.04513243958353996: 100%|██████████| 391/391 [00:01<00:00, 274.23it/s]\n",
            "Epoch: 95, Loss: 0.04975341632962227: 100%|██████████| 391/391 [00:01<00:00, 274.62it/s]\n",
            "Epoch: 96, Loss: 0.0491405613720417: 100%|██████████| 391/391 [00:01<00:00, 275.32it/s]\n",
            "Epoch: 97, Loss: 0.049490805715322495: 100%|██████████| 391/391 [00:01<00:00, 275.84it/s]\n",
            "Epoch: 98, Loss: 0.0494050532579422: 100%|██████████| 391/391 [00:01<00:00, 274.16it/s]\n",
            "Epoch: 99, Loss: 0.04816671460866928: 100%|██████████| 391/391 [00:01<00:00, 276.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x):\n",
        "  with torch.no_grad():\n",
        "    logits = forward_pass_2(x)\n",
        "    preds = F.softmax(logits, dim=1)\n",
        "  return preds"
      ],
      "metadata": {
        "id": "TlDPhPajTm5H"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_tensor = torch.from_numpy(x_valid).float().reshape(-1, 1, 28, 28).to(device)\n",
        "y_test_tensor = torch.from_numpy(y_valid).long().to(device)\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "batch_size = 128 # Use the same batch size as in training\n",
        "\n",
        "for i in range(0, x_test_tensor.shape[0], batch_size):\n",
        "    inp_batch = x_test_tensor[i:i+batch_size]\n",
        "    target_batch = y_test_tensor[i:i+batch_size]\n",
        "\n",
        "    preds = predict(inp_batch)\n",
        "    predicted_labels = torch.argmax(preds, dim=1)\n",
        "\n",
        "    correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "    total_predictions += target_batch.size(0)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS-hGqoxT0aX",
        "outputId": "59016a8b-66dc-41fa-e30e-2c6ec0902c0a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.9771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎉 Wohoo! IT worked!"
      ],
      "metadata": {
        "id": "9DFKNykp2TyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_img = x_test_tensor[0].squeeze().cpu()\n",
        "plt.imshow(t_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "mTf0stciv_h0",
        "outputId": "87d848b9-bcbb-4399-952c-6cd26b40a1ad"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a8bb1b17cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHABJREFUeJzt3X9w1PW97/HXBpIVMFkMIdmkBAyo0AqkpxTSHH4US4aQnssFYayo7QGvAwMNngL+OulV0LZnUnGu9epFmNtjoZ4RVM4IXL2WezGYUGtCC8KhjDaHcKKEAwmVnuyGICGQz/2D69aVBPqNu3lnw/Mx850hu9939uPXHZ9+2W++8TnnnAAA6GFJ1gsAAFybCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDR33oBn9fR0aETJ04oNTVVPp/PejkAAI+cc2ppaVFOTo6Skro+z+l1ATpx4oRyc3OtlwEA+IIaGho0bNiwLp/vdQFKTU2VJE3Rt9VfycarAQB4dUHtekdvRv573pW4BWjdunV66qmn1NjYqPz8fD333HOaNGnSVec+/Wu3/kpWfx8BAoCE8//vMHq1j1HichHCK6+8olWrVmnNmjV67733lJ+fr+LiYp06dSoeLwcASEBxCdDTTz+txYsX695779VXvvIVbdiwQQMHDtQvfvGLeLwcACABxTxA58+f1/79+1VUVPTnF0lKUlFRkaqrqy/bv62tTeFwOGoDAPR9MQ/Qxx9/rIsXLyorKyvq8aysLDU2Nl62f3l5uQKBQGTjCjgAuDaY/yBqWVmZQqFQZGtoaLBeEgCgB8T8KriMjAz169dPTU1NUY83NTUpGAxetr/f75ff74/1MgAAvVzMz4BSUlI0YcIEVVRURB7r6OhQRUWFCgsLY/1yAIAEFZefA1q1apUWLlyor3/965o0aZKeeeYZtba26t57743HywEAElBcAnTnnXfqj3/8o1avXq3GxkZ99atf1c6dOy+7MAEAcO3yOeec9SI+KxwOKxAIaLrmcCcEAEhAF1y7KrVDoVBIaWlpXe5nfhUcAODaRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz0t14AcDUdU//K88yJFee79VpTcv/N80zQH/Y8s6t8queZtoDP80zWP9d6npGki6f/1K05wAvOgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFD2q3w03eJ55+p+e9zwzJtnveaYnrf5vv++R19n10IBuzT365H/xPDPk59Xdei1cuzgDAgCYIEAAABMxD9Djjz8un88XtY0ZMybWLwMASHBx+Qzo1ltv1VtvvfXnF+nPR00AgGhxKUP//v0VDAbj8a0BAH1EXD4DOnLkiHJycjRy5Ejdc889OnbsWJf7trW1KRwOR20AgL4v5gEqKCjQpk2btHPnTq1fv1719fWaOnWqWlpaOt2/vLxcgUAgsuXm5sZ6SQCAXijmASopKdEdd9yh8ePHq7i4WG+++aaam5v16quvdrp/WVmZQqFQZGtoaIj1kgAAvVDcrw4YPHiwbrnlFtXV1XX6vN/vl9/fu39oEAAQe3H/OaAzZ87o6NGjys7OjvdLAQASSMwD9OCDD6qqqkoffvih3n33Xd1+++3q16+f7rrrrli/FAAggcX8r+COHz+uu+66S6dPn9bQoUM1ZcoU1dTUaOjQobF+KQBAAvM555z1Ij4rHA4rEAhouuaovy/ZejmIsX5D0j3P3LjzrOeZD5qzPM9I0rHfe/+r4uHjTnqemZFV63nmP6X+i+eZrH7tnmck6dfnvuR55pczv+l55sKHXf+IBhLXBdeuSu1QKBRSWlpal/txLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETcfyEd8FkXT//J88zRid5fJ0UfeR+SdFM357z6ta7zPFM9bJ7nmfcf9X5TUUmqm73B88w/zB3meSb4DDcjvZZxBgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3A0bSBAXjv+755mh1cO792KzvY+Ex5/3PBP0/jLoQzgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSIEH0D2Z5npn6d3vjsJLOZQWbe+y10DdwBgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpICBjql/5Xnmjp//b88z30tt9DwjSS+Eh3meSV/p/XUueh9BH8IZEADABAECAJjwHKA9e/Zo9uzZysnJkc/n0/bt26Oed85p9erVys7O1oABA1RUVKQjR47Ear0AgD7Cc4BaW1uVn5+vdevWdfr82rVr9eyzz2rDhg3au3evBg0apOLiYp07d+4LLxYA0Hd4vgihpKREJSUlnT7nnNMzzzyjRx99VHPmzJEkvfjii8rKytL27du1YMGCL7ZaAECfEdPPgOrr69XY2KiioqLIY4FAQAUFBaquru50pq2tTeFwOGoDAPR9MQ1QY+OlSz6zsqJ/d31WVlbkuc8rLy9XIBCIbLm5ubFcEgCglzK/Cq6srEyhUCiyNTQ0WC8JANADYhqgYDAoSWpqaop6vKmpKfLc5/n9fqWlpUVtAIC+L6YBysvLUzAYVEVFReSxcDisvXv3qrCwMJYvBQBIcJ6vgjtz5ozq6uoiX9fX1+vgwYNKT0/X8OHDtWLFCv3kJz/RzTffrLy8PD322GPKycnR3LlzY7luAECC8xygffv26bbbbot8vWrVKknSwoULtWnTJj388MNqbW3VkiVL1NzcrClTpmjnzp267rrrYrdqAEDC8znnnPUiPiscDisQCGi65qi/L9l6OcBVNa74a88zPy7d5Hnmbwae8Txz6uJZzzOS9J0VD3ieGfja3m69FvqeC65dldqhUCh0xc/1za+CAwBcmwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jABJBvxtu6NZc7erRnmfe/85/9zzTX/08z/z+fLvnmb//zjLPM5I08Hfc2RrxxxkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5GiTwpt6d7NSP913PPdmPJ+Y9HJ//IdzzPX/Q/v/0z+3/3O8wzQUzgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS9EklOe9bL+GKkv9xiOcZ/5t747ASwA5nQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Gij7phXendWuubHbP3MT0/zz7nOeZsf95meeZMT/5k+cZSbpYV9+tOcALzoAAACYIEADAhOcA7dmzR7Nnz1ZOTo58Pp+2b98e9fyiRYvk8/mitlmzZsVqvQCAPsJzgFpbW5Wfn69169Z1uc+sWbN08uTJyLZly5YvtEgAQN/j+SKEkpISlZSUXHEfv9+vYDDY7UUBAPq+uHwGVFlZqczMTI0ePVrLli3T6dOnu9y3ra1N4XA4agMA9H0xD9CsWbP04osvqqKiQk8++aSqqqpUUlKiixcvdrp/eXm5AoFAZMvNzY31kgAAvVDMfw5owYIFkT+PGzdO48eP16hRo1RZWakZM2Zctn9ZWZlWrVoV+TocDhMhALgGxP0y7JEjRyojI0N1dXWdPu/3+5WWlha1AQD6vrgH6Pjx4zp9+rSys7Pj/VIAgATi+a/gzpw5E3U2U19fr4MHDyo9PV3p6el64oknNH/+fAWDQR09elQPP/ywbrrpJhUXF8d04QCAxOY5QPv27dNtt90W+frTz28WLlyo9evX69ChQ/rlL3+p5uZm5eTkaObMmfrxj38sv98fu1UDABKezznnrBfxWeFwWIFAQNM1R/19ydbLQYJKSk3t1lzL1qGeZx4c9X89z8we2DM/bvDrc927zuiH/3WJ55nUl2u69Vroey64dlVqh0Kh0BU/1+decAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDB3bCBz0gaNMjzjC8lxfPM64crPM/0pNMdn3ieue35hzzPDCt/1/MMej/uhg0A6NUIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBQw0DHlq55nhj75keeZf7qx5256+vrZrm862ZX1N98Uh5XAGjcjBQD0agQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAif7WC8C1pd8VbkzYlYvhcBxWYivpnYOeZ0LzszzPzHhxnucZSaq49TXPM7MHev/39PORN3qeufBvH3qeQe/EGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkaLbkvK/7Hnm77dt8Tyz+Hd/63km6YPrPc9I0oBG53lm5D1HPM8M7H/e88y3bjjgeeZ7qY2eZ7rrpZZMzzPcWPTaxhkQAMAEAQIAmPAUoPLyck2cOFGpqanKzMzU3LlzVVtbG7XPuXPnVFpaqiFDhuj666/X/Pnz1dTUFNNFAwASn6cAVVVVqbS0VDU1Ndq1a5fa29s1c+ZMtba2RvZZuXKlXn/9dW3dulVVVVU6ceKE5s3r3i/FAgD0XZ4uQti5c2fU15s2bVJmZqb279+vadOmKRQK6YUXXtDmzZv1rW99S5K0ceNGffnLX1ZNTY2+8Y1vxG7lAICE9oU+AwqFQpKk9PR0SdL+/fvV3t6uoqKiyD5jxozR8OHDVV1d3en3aGtrUzgcjtoAAH1ftwPU0dGhFStWaPLkyRo7dqwkqbGxUSkpKRo8eHDUvllZWWps7Pxy0PLycgUCgciWm5vb3SUBABJItwNUWlqqw4cP6+WXX/5CCygrK1MoFIpsDQ0NX+j7AQASQ7d+EHX58uV64403tGfPHg0bNizyeDAY1Pnz59Xc3Bx1FtTU1KRgMNjp9/L7/fL7/d1ZBgAggXk6A3LOafny5dq2bZt2796tvLy8qOcnTJig5ORkVVRURB6rra3VsWPHVFhYGJsVAwD6BE9nQKWlpdq8ebN27Nih1NTUyOc6gUBAAwYMUCAQ0H333adVq1YpPT1daWlpuv/++1VYWMgVcACAKJ4CtH79eknS9OnTox7fuHGjFi1aJEn62c9+pqSkJM2fP19tbW0qLi7W888/H5PFAgD6Dp9zzvvdF+MoHA4rEAhouuaovy/Zejm4gvqfev9r1X/92/WeZy66Ds8zvV0/n/frf3ryOBy7cNbzzPceeMDzzKB/3ut5Br3fBdeuSu1QKBRSWlpal/txLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY6NZvRAUkqf2GC9ZLuKZMOXSH55nr/yG1W6+V8u//4XlmUD13toY3nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSm6bfTfHfI889dvL/U807og5Hnm1qGNnmck6fiZwd2a86rjf2Z6ngn8rwOeZ1z7ec8zksRtZtETOAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1J0m2tr8zyT+nJNN2Y8j+i09xFJ0gD9Rzcnvar3POHisArAEmdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwISnAJWXl2vixIlKTU1VZmam5s6dq9ra2qh9pk+fLp/PF7UtXbo0posGACQ+TwGqqqpSaWmpampqtGvXLrW3t2vmzJlqbW2N2m/x4sU6efJkZFu7dm1MFw0ASHyefiPqzp07o77etGmTMjMztX//fk2bNi3y+MCBAxUMBmOzQgBAn/SFPgMKhUKSpPT09KjHX3rpJWVkZGjs2LEqKyvT2bNnu/webW1tCofDURsAoO/zdAb0WR0dHVqxYoUmT56ssWPHRh6/++67NWLECOXk5OjQoUN65JFHVFtbq9dee63T71NeXq4nnniiu8sAACQon3POdWdw2bJl+tWvfqV33nlHw4YN63K/3bt3a8aMGaqrq9OoUaMue76trU1tbW2Rr8PhsHJzczVdc9Tfl9ydpQEADF1w7arUDoVCIaWlpXW5X7fOgJYvX6433nhDe/bsuWJ8JKmgoECSugyQ3++X3+/vzjIAAAnMU4Ccc7r//vu1bds2VVZWKi8v76ozBw8elCRlZ2d3a4EAgL7JU4BKS0u1efNm7dixQ6mpqWpsbJQkBQIBDRgwQEePHtXmzZv17W9/W0OGDNGhQ4e0cuVKTZs2TePHj4/LPwAAIDF5+gzI5/N1+vjGjRu1aNEiNTQ06Lvf/a4OHz6s1tZW5ebm6vbbb9ejjz56xb8H/KxwOKxAIMBnQACQoOLyGdDVWpWbm6uqqiov3xIAcI3iXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP9rRfwec45SdIFtUvOeDEAAM8uqF3Sn/973pVeF6CWlhZJ0jt603glAIAvoqWlRYFAoMvnfe5qiephHR0dOnHihFJTU+Xz+aKeC4fDys3NVUNDg9LS0oxWaI/jcAnH4RKOwyUch0t6w3FwzqmlpUU5OTlKSur6k55edwaUlJSkYcOGXXGftLS0a/oN9imOwyUch0s4DpdwHC6xPg5XOvP5FBchAABMECAAgImECpDf79eaNWvk9/utl2KK43AJx+ESjsMlHIdLEuk49LqLEAAA14aEOgMCAPQdBAgAYIIAAQBMECAAgImECdC6det044036rrrrlNBQYF++9vfWi+pxz3++OPy+XxR25gxY6yXFXd79uzR7NmzlZOTI5/Pp+3bt0c975zT6tWrlZ2drQEDBqioqEhHjhyxWWwcXe04LFq06LL3x6xZs2wWGyfl5eWaOHGiUlNTlZmZqblz56q2tjZqn3Pnzqm0tFRDhgzR9ddfr/nz56upqcloxfHxlxyH6dOnX/Z+WLp0qdGKO5cQAXrllVe0atUqrVmzRu+9957y8/NVXFysU6dOWS+tx9166606efJkZHvnnXeslxR3ra2tys/P17p16zp9fu3atXr22We1YcMG7d27V4MGDVJxcbHOnTvXwyuNr6sdB0maNWtW1Ptjy5YtPbjC+KuqqlJpaalqamq0a9cutbe3a+bMmWptbY3ss3LlSr3++uvaunWrqqqqdOLECc2bN89w1bH3lxwHSVq8eHHU+2Ht2rVGK+6CSwCTJk1ypaWlka8vXrzocnJyXHl5ueGqet6aNWtcfn6+9TJMSXLbtm2LfN3R0eGCwaB76qmnIo81Nzc7v9/vtmzZYrDCnvH54+CccwsXLnRz5swxWY+VU6dOOUmuqqrKOXfp331ycrLbunVrZJ8PPvjASXLV1dVWy4y7zx8H55z75je/6X7wgx/YLeov0OvPgM6fP6/9+/erqKgo8lhSUpKKiopUXV1tuDIbR44cUU5OjkaOHKl77rlHx44ds16Sqfr6ejU2Nka9PwKBgAoKCq7J90dlZaUyMzM1evRoLVu2TKdPn7ZeUlyFQiFJUnp6uiRp//79am9vj3o/jBkzRsOHD+/T74fPH4dPvfTSS8rIyNDYsWNVVlams2fPWiyvS73uZqSf9/HHH+vixYvKysqKejwrK0t/+MMfjFZlo6CgQJs2bdLo0aN18uRJPfHEE5o6daoOHz6s1NRU6+WZaGxslKRO3x+fPnetmDVrlubNm6e8vDwdPXpUP/zhD1VSUqLq6mr169fPenkx19HRoRUrVmjy5MkaO3aspEvvh5SUFA0ePDhq3778fujsOEjS3XffrREjRignJ0eHDh3SI488otraWr322muGq43W6wOEPyspKYn8efz48SooKNCIESP06quv6r777jNcGXqDBQsWRP48btw4jR8/XqNGjVJlZaVmzJhhuLL4KC0t1eHDh6+Jz0GvpKvjsGTJksifx40bp+zsbM2YMUNHjx7VqFGjenqZner1fwWXkZGhfv36XXYVS1NTk4LBoNGqeofBgwfrlltuUV1dnfVSzHz6HuD9cbmRI0cqIyOjT74/li9frjfeeENvv/121K9vCQaDOn/+vJqbm6P276vvh66OQ2cKCgokqVe9H3p9gFJSUjRhwgRVVFREHuvo6FBFRYUKCwsNV2bvzJkzOnr0qLKzs62XYiYvL0/BYDDq/REOh7V3795r/v1x/PhxnT59uk+9P5xzWr58ubZt26bdu3crLy8v6vkJEyYoOTk56v1QW1urY8eO9an3w9WOQ2cOHjwoSb3r/WB9FcRf4uWXX3Z+v99t2rTJvf/++27JkiVu8ODBrrGx0XppPeqBBx5wlZWVrr6+3v3mN79xRUVFLiMjw506dcp6aXHV0tLiDhw44A4cOOAkuaefftodOHDAffTRR845537605+6wYMHux07drhDhw65OXPmuLy8PPfJJ58Yrzy2rnQcWlpa3IMPPuiqq6tdfX29e+utt9zXvvY1d/PNN7tz585ZLz1mli1b5gKBgKusrHQnT56MbGfPno3ss3TpUjd8+HC3e/dut2/fPldYWOgKCwsNVx17VzsOdXV17kc/+pHbt2+fq6+vdzt27HAjR45006ZNM155tIQIkHPOPffcc2748OEuJSXFTZo0ydXU1FgvqcfdeeedLjs726WkpLgvfelL7s4773R1dXXWy4q7t99+20m6bFu4cKFz7tKl2I899pjLyspyfr/fzZgxw9XW1touOg6udBzOnj3rZs6c6YYOHeqSk5PdiBEj3OLFi/vc/6R19s8vyW3cuDGyzyeffOK+//3vuxtuuMENHDjQ3X777e7kyZN2i46Dqx2HY8eOuWnTprn09HTn9/vdTTfd5B566CEXCoVsF/45/DoGAICJXv8ZEACgbyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPw/ngXm62JKsKEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_preds = predict(x_test_tensor[0].unsqueeze(0))\n",
        "print(t_preds)\n",
        "t_preds.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2UR6vEkyFxX",
        "outputId": "f6d3e87c-afcf-4e8e-cbac-d89a31dd53c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.3910e-16, 4.3141e-14, 1.6882e-06, 9.9999e-01, 3.1150e-16, 7.2040e-06,\n",
            "         2.0771e-10, 4.4437e-13, 4.4248e-07, 2.0838e-11]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}